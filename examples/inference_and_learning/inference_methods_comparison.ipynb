{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import tree_util as jtu, nn, vmap, lax\n",
    "from jax.experimental import sparse\n",
    "from pymdp.jax.agent import Agent\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pymdp.jax.inference import smoothing_ovf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up generative model and a sequence of observations. The A tensors, B tensors and observations are specified in such a way that  only later observations ($o_{t > 1}$) help disambiguate hidden states at earlier time points. This will demonstrate the importance of \"smoothing\" or retrospective inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = [3, 2]\n",
    "num_obs = [2]\n",
    "n_batch = 2\n",
    "\n",
    "A_1 = jnp.array([[1.0, 1.0, 1.0], [0.0,  0.0,  1.]])\n",
    "A_2 = jnp.array([[1.0, 1.0], [1., 0.]])\n",
    "\n",
    "A_tensor = A_1[..., None] * A_2[:, None]\n",
    "\n",
    "A_tensor /= A_tensor.sum(0)\n",
    "\n",
    "A = [jnp.broadcast_to(A_tensor, (n_batch, num_obs[0], 3, 2)) ]\n",
    "\n",
    "# create two transition matrices, one for each state factor\n",
    "B_1 = jnp.broadcast_to(\n",
    "    jnp.array([[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]]), (n_batch, 3, 3)\n",
    ")\n",
    "\n",
    "B_2 = jnp.broadcast_to(\n",
    "        jnp.array([[0.0, 1.0], [1.0, 0.0]]), (n_batch, 2, 2)\n",
    "    )\n",
    "\n",
    "B = [B_1[..., None], B_2[..., None]]\n",
    "\n",
    "# for the single modality, a sequence over time of observations (one hot vectors)\n",
    "obs = [jnp.broadcast_to(jnp.array([[1., 0.], # observation 0 is ambiguous with respect state factors\n",
    "                                    [1., 0], # observation 0 is ambiguous with respect state factors\n",
    "                                    [1., 0], # observation 0 is ambiguous with respect state factors\n",
    "                                    [0., 1.]])[:, None], (4, n_batch, num_obs[0]) )] # observation 1 provides information about exact state of both factors \n",
    "C = [jnp.zeros((n_batch, num_obs[0]))] # flat preferences\n",
    "D = [jnp.ones((n_batch, 3)) / 3., jnp.ones((n_batch, 2)) / 2.] # flat prior\n",
    "E = jnp.ones((n_batch, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(A), A[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the `Agent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pA = None\n",
    "pB = None\n",
    "\n",
    "agents = Agent(\n",
    "        A=A,\n",
    "        B=B,\n",
    "        C=C,\n",
    "        D=D,\n",
    "        E=E,\n",
    "        pA=None,\n",
    "        pB=None,\n",
    "        policy_len=3,\n",
    "        control_fac_idx=None,\n",
    "        policies=None,\n",
    "        gamma=16.0,\n",
    "        alpha=16.0,\n",
    "        use_utility=True,\n",
    "        onehot_obs=True,\n",
    "        action_selection=\"deterministic\",\n",
    "        sampling_mode=\"full\",\n",
    "        inference_algo=\"ovf\",\n",
    "        num_iter=16,\n",
    "        learn_A=False,\n",
    "        learn_B=False,\n",
    "        apply_batch=False\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `obs` and `policies`, pass in the arguments `outcomes`, `past_actions`, `empirical_prior` and `qs_hist` to `agent.infer_states(...)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run first timestep of inference using `obs[0]`, no past actions, empirical prior set to actual prior, no qs_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior = agents.D\n",
    "# qs_hist = None\n",
    "# action_hist = []\n",
    "# t =0\n",
    "# first_obs = jtu.tree_map(lambda x: jnp.moveaxis(x[:t+1], 0, 1), obs)\n",
    "# beliefs = agents.infer_states(first_obs, past_actions=None, empirical_prior=prior, qs_hist=qs_hist)\n",
    "# actions = jnp.broadcast_to(agents.policies[0, 0], (2, 2))\n",
    "# prior, qs_hist = agents.update_empirical_prior(actions, beliefs)\n",
    "# action_hist.append(actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = agents.D\n",
    "qs_hist = None\n",
    "action_hist = []\n",
    "for t in range(len(obs[0])):\n",
    "    first_obs = jtu.tree_map(lambda x: jnp.moveaxis(x[:t+1], 0, 1), obs)\n",
    "    beliefs = agents.infer_states(first_obs, past_actions=None, empirical_prior=prior, qs_hist=qs_hist)\n",
    "    actions = jnp.broadcast_to(agents.policies[0, 0], (2, 2))\n",
    "    prior, qs_hist = agents.infer_empirical_prior(actions, beliefs)\n",
    "    action_hist.append(actions)\n",
    "\n",
    "beliefs = jtu.tree_map(lambda x, y: jnp.concatenate([x[:, None], y], 1), agents.D, beliefs)\n",
    "\n",
    "smoothed_beliefs = vmap(smoothing_ovf)(beliefs, agents.B, jnp.stack(action_hist, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_B = jtu.tree_map(lambda b: sparse.BCOO.fromdense(b, n_batch=n_batch), agents.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse.sparsify(jnp.stack)([sparse_B[0], sparse_B[0]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_beliefs_sparse = vmap(smoothing_ovf)(beliefs, sparse_B, jnp.stack(action_hist, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the non-vmapped version of `smoothing_ovf`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_first = lambda pytree: jtu.tree_map(lambda leaf: leaf[0], pytree)\n",
    "\n",
    "beliefs_single = take_first(beliefs)\n",
    "sparse_B_single = jtu.tree_map(lambda b: sparse.BCOO.fromdense(b[0]), agents.B)\n",
    "actions_single = jnp.stack(action_hist, 1)[0]\n",
    "\n",
    "smoothed_beliefs = smoothing_ovf(beliefs_single, sparse_B_single, actions_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can plot that pair of filtering / smoothing distributions for the single batch / single agent, that we ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 8), sharex=True)\n",
    "\n",
    "sns.heatmap(beliefs_single[0].mT, ax=axes[0, 0], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "sns.heatmap(beliefs_single[1].mT, ax=axes[1, 0], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "\n",
    "sns.heatmap(smoothed_beliefs[0][0].mT, ax=axes[0, 1], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "sns.heatmap(smoothed_beliefs[1][0].mT, ax=axes[1, 1], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "\n",
    "axes[0, 0].set_title('Filtered beliefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_id, batch_id = 0, 0\n",
    "# filtered_qs = beliefs[f_id][batch_id] # this assuming the code below is being tree_mapped over factors (first index is factor_id), and vmapped over batches (second index is batch_id)\n",
    "# sparse_b = sparse_B[f_id][batch_id]\n",
    "# b = agents.B[f_id][batch_id]\n",
    "# past_actions = jnp.stack(action_hist, 1)\n",
    "# actions = past_actions[batch_id][...,f_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qs_last = filtered_qs[-1]\n",
    "# qs_filter = filtered_qs[:-1]\n",
    "# # time_b = jnp.moveaxis(b[..., actions], -1, 0)\n",
    "# time_b = sparse_b[...,actions].transpose([sparse_b.ndim-1] + list(range(sparse_b.ndim-1)))\n",
    "# qs_joint= time_b * jnp.expand_dims(qs_filter, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse_b[...,actions].transpose([sparse_b.ndim-1] + list(range(sparse_b.ndim-1))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qs_last = filtered_qs[-1]\n",
    "# qs_filter = filtered_qs[:-1]\n",
    "\n",
    "# # conditional dist - timestep x s_{t+1} | s_{t}\n",
    "# time_b = jnp.moveaxis(b[..., actions], -1, 0)\n",
    "\n",
    "# # joint dist - timestep x s_{t+1} x s_{t}\n",
    "# qs_joint = time_b * jnp.expand_dims(qs_filter, -1)\n",
    "\n",
    "# # cond dist - timestep x s_{t} | s_{t+1}\n",
    "# qs_backward_cond = jnp.moveaxis(\n",
    "#     qs_joint / qs_joint.sum(-2, keepdims=True), -2, -1\n",
    "# )\n",
    "\n",
    "# def step_fn(qs_smooth_past, backward_b):\n",
    "#     qs_joint = backward_b * qs_smooth_past\n",
    "#     qs_smooth = qs_joint.sum(-1)\n",
    "    \n",
    "#     return qs_smooth, (qs_smooth, qs_joint)\n",
    "\n",
    "# # seq_qs will contain a sequence of smoothed marginals and joints\n",
    "# _, seq_qs = lax.scan(\n",
    "#     step_fn,\n",
    "#     qs_last,\n",
    "#     qs_backward_cond,\n",
    "#     reverse=True,\n",
    "#     unroll=2\n",
    "# )\n",
    "\n",
    "# # we add the last filtered belief to smoothed beliefs\n",
    "# qs_smooth_all = jnp.concatenate([seq_qs[0], jnp.expand_dims(qs_last, 0)], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 8), sharex=True)\n",
    "\n",
    "sns.heatmap(beliefs[0][0].mT, ax=axes[0, 0], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "sns.heatmap(beliefs[1][0].mT, ax=axes[1, 0], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "\n",
    "sns.heatmap(smoothed_beliefs[0][0][0].mT, ax=axes[0, 1], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "sns.heatmap(smoothed_beliefs[1][0][0].mT, ax=axes[1, 1], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "\n",
    "axes[0, 0].set_title('Filtered beliefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opt_einsum import contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sparse_B[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contract('ijk->k', sparse_B[0][...,0].todense())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
