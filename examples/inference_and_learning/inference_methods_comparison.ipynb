{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from pymdp.jax.agent import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up generative model and a sequence of observations. The A tensors, B tensors and observations are specified in such a way that  only later observations ($o_{t > 1}$) help disambiguate hidden states at earlier time points. This will demonstrate the importance of \"smoothing\" or retrospective inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = [3, 2]\n",
    "num_obs = [3]\n",
    "\n",
    "A_tensor = jnp.stack([jnp.array([[0.5, 0.5, 0.], \n",
    "                                [0.0,  0.0,  1.], \n",
    "                                [0.5, 0.5, 0.]]\n",
    "                            ), jnp.array([[1./3, 1./3, 1./3], \n",
    "                                            [1./3, 1./3, 1./3], \n",
    "                                            [1./3, 1./3, 1./3]]\n",
    "                            )], axis=-1)\n",
    "\n",
    "A = [ jnp.broadcast_to(A_tensor, (2, 3, 3, 2)) ]\n",
    "\n",
    "# create two B matrices, one for each action\n",
    "B_1 = jnp.broadcast_to(jnp.array([[0.0, 0.75, 0.0],\n",
    "                                [0.0, 0.25, 1.0],\n",
    "                                [1.0, 0.0, 0.0]]\n",
    "            ), (2, 3, 3))\n",
    "\n",
    "B_2 = jnp.broadcast_to(jnp.array([[0.0, 0.25, 0.0],\n",
    "                                [0.0, 0.75, 0.0],\n",
    "                                [1.0, 0.0, 1.0]]\n",
    "            ), (2, 3, 3))\n",
    "\n",
    "B_uncontrollable = jnp.expand_dims(\n",
    "    jnp.broadcast_to(\n",
    "        jnp.array([[1.0, 0.0], [0.0, 1.0]]), (2, 2, 2)\n",
    "    ), \n",
    "    -1\n",
    ")\n",
    "\n",
    "B = [jnp.stack([B_1, B_2], axis=-1), B_uncontrollable]\n",
    "\n",
    "# create a policy-dependent sequence of B matrices\n",
    "\n",
    "policy_1 = jnp.array([ [0, 0],\n",
    "                        [1, 0],\n",
    "                        [1, 0] ]\n",
    "                    )\n",
    "\n",
    "policy_2 = jnp.array([ [1, 0],\n",
    "                        [1, 0],\n",
    "                        [1, 0] ]\n",
    "                    )\n",
    "\n",
    "policy_3 = jnp.array([ [1, 0],\n",
    "                        [0, 0],\n",
    "                        [1, 0] ]\n",
    "                    )\n",
    "\n",
    "all_policies = [policy_1, policy_2, policy_3]\n",
    "n_policies = len(all_policies)\n",
    "all_policies = list(jnp.stack(all_policies).transpose(2, 0, 1)) # `n_factors` lists, each with matrix of shape `(n_policies, n_time_steps)`\n",
    "\n",
    "# for the single modality, a sequence over time of observations (one hot vectors)\n",
    "obs = [jnp.broadcast_to(jnp.array([[1., 0., 0.], # observation 0 is ambiguous with respect to hidden state_1 and hidden_state 2\n",
    "                                    [0., 1., 0.],  # observation 1 yields certain inference over hidden_state_1 = 2\n",
    "                                    [0., 0., 1.], # observation 2 is ambiguous with respect to hidden state_1 and hidden_state 2\n",
    "                                    [1., 0., 0.]])[:, None], (4, 2, 3) )] # observation 0 is ambiguous with respect to hidden state_1 and hidden_state 2\n",
    "\n",
    "C = [jnp.ones((2,3))] # flat preferences\n",
    "D = [jnp.ones((2, 3)) / 3., jnp.ones((2, 2)) / 2.] # flat prior\n",
    "E = jnp.ones((2,n_policies))/n_policies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the `Agent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pA = None\n",
    "pB = None\n",
    "\n",
    "agents = Agent(\n",
    "        A=A,\n",
    "        B=B,\n",
    "        C=C,\n",
    "        D=D,\n",
    "        E=E,\n",
    "        pA=None,\n",
    "        pB=None,\n",
    "        policy_len=3,\n",
    "        control_fac_idx=None,\n",
    "        policies=None,\n",
    "        gamma=16.0,\n",
    "        alpha=16.0,\n",
    "        use_utility=True,\n",
    "        action_selection=\"deterministic\",\n",
    "        sampling_mode=\"full\",\n",
    "        inference_algo=\"ovf\",\n",
    "        num_iter=16,\n",
    "        learn_A=False,\n",
    "        learn_B=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `obs` and `policies`, pass in the arguments `outcomes`, `past_actions`, `empirical_prior` and `qs_hist` to `agent.infer_states(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "vmap got inconsistent sizes for array axes to be mapped:\n  * most axes (13 of them) had size 2, e.g. axis 0 of args[0].A[0] of type float32[2,3,3,2];\n  * one axis had size 4: axis 0 of args[1][0] of type float32[4,2,3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/pymdp_dev_env/lib/python3.12/site-packages/jax/_src/api.py:1296\u001b[0m, in \u001b[0;36m_mapped_axis_size\u001b[0;34m(fn, tree, vals, dims, name)\u001b[0m\n\u001b[1;32m   1294\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1295\u001b[0m     msg\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  * some axes (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mct\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of them) had size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, e.g. axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1296\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(msg)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: vmap got inconsistent sizes for array axes to be mapped:\n  * most axes (13 of them) had size 2, e.g. axis 0 of args[0].A[0] of type float32[2,3,3,2];\n  * one axis had size 4: axis 0 of args[1][0] of type float32[4,2,3]"
     ]
    }
   ],
   "source": [
    "beliefs = agents.infer_states(outcomes, past_actions, empirical_prior, qs_hist, mask=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
