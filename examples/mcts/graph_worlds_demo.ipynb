{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from jax import random as jr, lax, vmap, nn\n",
    "from pymdp.jax.envs import GraphEnv\n",
    "\n",
    "import networkx as nx\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_connected_clusters(cluster_size=2, connections=2):\n",
    "    edges = []\n",
    "    connecting_node = 0\n",
    "    while connecting_node < connections * cluster_size:\n",
    "        edges += [(connecting_node, a) for a in range(connecting_node + 1, connecting_node + cluster_size + 1)]\n",
    "        connecting_node = len(edges)\n",
    "    graph = nx.Graph()\n",
    "    graph.add_edges_from(edges)\n",
    "    return graph, {\n",
    "        \"locations\": [\n",
    "            (f\"hallway {i}\" if len(list(graph.neighbors(loc))) > 1 else f\"room {i}\")\n",
    "            for i, loc in enumerate(graph.nodes)\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph, _ = generate_connected_clusters(cluster_size=2, connections=2)\n",
    "nx.draw(graph, with_labels=True, font_weight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 12:10:10.915385: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.3 which is older than the ptxas CUDA version (12.5.40). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "key = jr.PRNGKey(0)\n",
    "env = GraphEnv(graph, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "(1, 2)\n",
      "([Array([0], dtype=int32), Array([0], dtype=int32)], GraphEnv(\n",
      "  params={\n",
      "    'A':\n",
      "    [f32[1,5,5], f32[1,2,5,6]],\n",
      "    'B':\n",
      "    [f32[1,5,5,5], f32[1,6,6,1]],\n",
      "    'D':\n",
      "    [f32[1,5], f32[1,6]]\n",
      "  },\n",
      "  states=[[i32[1], i32[1]], [i32[1], i32[1]]],\n",
      "  dependencies={'A': [[0], [0, 1]], 'B': [[0], [1]]}\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "keys = jr.split(key, batch_size + 1)\n",
    "key = keys[-1]\n",
    "\n",
    "action = jnp.broadcast_to(jnp.array([4, 0]), (batch_size, 2))\n",
    "print(action.shape)\n",
    "\n",
    "_keys = keys[:batch_size]\n",
    "print(jnp.shape(_keys))\n",
    "obs = env.step(_keys, action)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp.jax.agent import Agent\n",
    "\n",
    "A = [a for a in env.params[\"A\"]]\n",
    "B = [b for b in env.params[\"B\"]]\n",
    "A_dependencies = env.dependencies[\"A\"]\n",
    "B_dependencies = env.dependencies[\"B\"]\n",
    "\n",
    "C = [jnp.zeros(a.shape[:2]) for a in A]\n",
    "C[1] = C[1].at[1].set(1.0)\n",
    "\n",
    "D = [jnp.ones(b.shape[:2]) for b in B]\n",
    "\n",
    "agent = Agent(A, B, C, D, None, None, None, A_dependencies=A_dependencies, B_dependencies=B_dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1, 5), (1, 1, 6)]\n"
     ]
    }
   ],
   "source": [
    "# add a time dimension\n",
    "qs = [jnp.broadcast_to(d, (1,) + d.shape) for d in D]\n",
    "\n",
    "print([s.shape for s in qs])\n",
    "q_pi, nefe = agent.infer_policies(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_keys = jr.split(key, batch_size + 1)\n",
    "_keys = keys[:batch_size]\n",
    "key = keys[-1]\n",
    "actions = agent.sample_action(q_pi, rng_key=_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_keys = jr.split(key, batch_size + 1)\n",
    "_keys = keys[:batch_size]\n",
    "key = keys[-1]\n",
    "obs, env = env.step(_keys, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Array([0], dtype=int32), Array([0], dtype=int32)]\n",
      "[(1, 1, 5), (1, 1, 6)]\n",
      "(1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Array([[[0.16048184, 0.35807264, 0.16048184, 0.16048184, 0.16048184]]],      dtype=float32),\n",
       " Array([[[3.0379263e-03, 2.4523251e-06, 3.0379263e-03, 3.0379263e-03,\n",
       "          3.0379263e-03, 9.8784572e-01]]], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(obs)\n",
    "# add time dim\n",
    "obs_b = [jnp.broadcast_to(o, (1,) + o.shape) for o in obs]\n",
    "\n",
    "print([s.shape for s in qs])\n",
    "print(actions.shape)\n",
    "prior, _ = agent.update_empirical_prior(actions, qs)\n",
    "\n",
    "agent.infer_states(obs_b, None, prior, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'efe_policy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmctx\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m policy_output \u001b[38;5;241m=\u001b[39m \u001b[43mefe_policy\u001b[49m(\n\u001b[1;32m      4\u001b[0m     agents,\n\u001b[1;32m      5\u001b[0m     rng_key,\n\u001b[1;32m      6\u001b[0m     root,\n\u001b[1;32m      7\u001b[0m     recurrent_fn,\n\u001b[1;32m      8\u001b[0m     num_simulations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m      9\u001b[0m     tree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     max_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m48\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m tree \u001b[38;5;241m=\u001b[39m policy_output\u001b[38;5;241m.\u001b[39msearch_tree\n",
      "\u001b[0;31mNameError\u001b[0m: name 'efe_policy' is not defined"
     ]
    }
   ],
   "source": [
    "import mctx\n",
    "import chex\n",
    "from typing import Optional\n",
    "from mctx._src.policies import _mask_invalid_actions\n",
    "from mctx._src import action_selection\n",
    "from mctx._src import base\n",
    "from mctx._src import qtransforms\n",
    "from mctx._src import search\n",
    "from mctx._src import seq_halving\n",
    "\n",
    "def gumbel_si_policy(\n",
    "    params: base.Params,\n",
    "    rng_key: chex.PRNGKey,\n",
    "    root: base.RootFnOutput,\n",
    "    recurrent_fn: base.RecurrentFn,\n",
    "    num_simulations: int,\n",
    "    invalid_actions: Optional[chex.Array] = None,\n",
    "    max_depth: Optional[int] = None,\n",
    "    loop_fn: base.LoopFn = lax.fori_loop,\n",
    "    *,\n",
    "    qtransform: base.QTransform = qtransforms.qtransform_completed_by_mix_value,\n",
    "    max_num_considered_actions: int = 16,\n",
    "    gumbel_scale: chex.Numeric = 1.,\n",
    ") -> base.PolicyOutput[action_selection.GumbelMuZeroExtraData]:\n",
    "  \"\"\"Runs Gumbel MuZero search and returns the `PolicyOutput`.\n",
    "\n",
    "  This policy implements Full Gumbel MuZero from\n",
    "  \"Policy improvement by planning with Gumbel\".\n",
    "  https://openreview.net/forum?id=bERaNdoegnO\n",
    "\n",
    "  At the root of the search tree, actions are selected by Sequential Halving\n",
    "  with Gumbel. At non-root nodes (aka interior nodes), actions are selected by\n",
    "  the Full Gumbel MuZero deterministic action selection.\n",
    "\n",
    "  In the shape descriptions, `B` denotes the batch dimension.\n",
    "\n",
    "  Args:\n",
    "    params: params to be forwarded to root and recurrent functions.\n",
    "    rng_key: random number generator state, the key is consumed.\n",
    "    root: a `(prior_logits, value, embedding)` `RootFnOutput`. The\n",
    "      `prior_logits` are from a policy network. The shapes are\n",
    "      `([B, num_actions], [B], [B, ...])`, respectively.\n",
    "    recurrent_fn: a callable to be called on the leaf nodes and unvisited\n",
    "      actions retrieved by the simulation step, which takes as args\n",
    "      `(params, rng_key, action, embedding)` and returns a `RecurrentFnOutput`\n",
    "      and the new state embedding. The `rng_key` argument is consumed.\n",
    "    num_simulations: the number of simulations.\n",
    "    invalid_actions: a mask with invalid actions. Invalid actions\n",
    "      have ones, valid actions have zeros in the mask. Shape `[B, num_actions]`.\n",
    "    max_depth: maximum search tree depth allowed during simulation.\n",
    "    loop_fn: Function used to run the simulations. It may be required to pass\n",
    "      hk.fori_loop if using this function inside a Haiku module.\n",
    "    qtransform: function to obtain completed Q-values for a node.\n",
    "    max_num_considered_actions: the maximum number of actions expanded at the\n",
    "      root node. A smaller number of actions will be expanded if the number of\n",
    "      valid actions is smaller.\n",
    "    gumbel_scale: scale for the Gumbel noise. Evalution on perfect-information\n",
    "      games can use gumbel_scale=0.0.\n",
    "\n",
    "  Returns:\n",
    "    `PolicyOutput` containing the proposed action, action_weights and the used\n",
    "    search tree.\n",
    "  \"\"\"\n",
    "  # Masking invalid actions.\n",
    "  root = root.replace(\n",
    "      prior_logits=_mask_invalid_actions(root.prior_logits, invalid_actions)\n",
    "  )\n",
    "\n",
    "  # Generating Gumbel.\n",
    "  rng_key, gumbel_rng = jr.split(rng_key)\n",
    "  gumbel = gumbel_scale * jr.gumbel(\n",
    "      gumbel_rng, shape=root.prior_logits.shape, dtype=root.prior_logits.dtype\n",
    "    )\n",
    "\n",
    "  # Searching.\n",
    "  extra_data = action_selection.GumbelMuZeroExtraData(root_gumbel=gumbel)\n",
    "  search_tree = search.search(\n",
    "      params=params,\n",
    "      rng_key=rng_key,\n",
    "      root=root,\n",
    "      recurrent_fn=recurrent_fn,\n",
    "      root_action_selection_fn=partial(\n",
    "          action_selection.gumbel_muzero_root_action_selection,\n",
    "          num_simulations=num_simulations,\n",
    "          max_num_considered_actions=max_num_considered_actions,\n",
    "          qtransform=qtransform,\n",
    "      ),\n",
    "      interior_action_selection_fn=partial(\n",
    "          action_selection.gumbel_muzero_interior_action_selection,\n",
    "          qtransform=qtransform,\n",
    "      ),\n",
    "      num_simulations=num_simulations,\n",
    "      max_depth=max_depth,\n",
    "      invalid_actions=invalid_actions,\n",
    "      extra_data=extra_data,\n",
    "      loop_fn=loop_fn)\n",
    "  summary = search_tree.summary()\n",
    "\n",
    "  # Acting with the best action from the most visited actions.\n",
    "  # The \"best\" action has the highest `gumbel + logits + q`.\n",
    "  # Inside the minibatch, the considered_visit can be different on states with\n",
    "  # a smaller number of valid actions.\n",
    "  considered_visit = jnp.max(summary.visit_counts, axis=-1, keepdims=True)\n",
    "  # The completed_qvalues include imputed values for unvisited actions.\n",
    "  completed_qvalues = vmap(qtransform, in_axes=[0, None])(  # pytype: disable=wrong-arg-types  # numpy-scalars  # pylint: disable=line-too-long\n",
    "      search_tree, search_tree.ROOT_INDEX\n",
    "    )\n",
    "  to_argmax = seq_halving.score_considered(\n",
    "      considered_visit,\n",
    "      gumbel,\n",
    "      root.prior_logits,\n",
    "      completed_qvalues,\n",
    "      summary.visit_counts\n",
    "    )\n",
    "  action = action_selection.masked_argmax(to_argmax, invalid_actions)\n",
    "\n",
    "  # Producing action_weights usable to train the policy network.\n",
    "  completed_search_logits = _mask_invalid_actions(\n",
    "      root.prior_logits + completed_qvalues, invalid_actions)\n",
    "  action_weights = nn.softmax(completed_search_logits)\n",
    "  return base.PolicyOutput(\n",
    "      action=action,\n",
    "      action_weights=action_weights,\n",
    "      search_tree=search_tree)\n",
    "\n",
    "\n",
    "#step, embedding = recurrent_fn(params, rng_key, action, embedding)\n",
    "\n",
    "def recurrent_fn(params, rng_key, action, embedding):\n",
    "  pass\n",
    "\n",
    "def _make_aif_recurrent_fn(policies):\n",
    "  \"\"\"Returns a recurrent_fn for a determistic bandit.\"\"\"\n",
    "\n",
    "  def recurrent_fn(agent, rng_key, action, embedding):\n",
    "    qs = embedding\n",
    "    # For the bandit, the reward will be non-zero only at the root.\n",
    "    reward = jnp.where(embedding == 0,\n",
    "                       qvalues[jnp.arange(action.shape[0]), action],\n",
    "                       0.0)\n",
    "    \n",
    "        G = []\n",
    "    # get exp info gain and utility for each action\n",
    "    rollout = lambda act: agent.update_empirical_prior(qs, act)\n",
    "    qs_next_pi = vmap(rollout)(policies)\n",
    "    qo_next_pi = jtu.tree_map( lambda a, q: a @ q, agent.A, qs_next)\n",
    "    neg_efe = exp_utility(qo_next_pi) + exp_info_gain(qs_next_pi, qo_next_pi)\n",
    "\n",
    "    # recursively branch the policy + outcome tree\n",
    "    for p in policies:\n",
    "       G_next_p = 0\n",
    "\n",
    "       for o in possible_outcomes:\n",
    "           prob = qo_next[o]\n",
    "           qs_next_posterior = agent.infer_states(qs_next, o)\n",
    "\n",
    "           G_next = expand(qs_next_posterior ...)\n",
    "           G_next_p += G_next * prob\n",
    "       G_next_p = q_pi[p] * G_next_p\n",
    "       G[p] += G_next_p\n",
    "       return G\n",
    "    \n",
    "    # use fake discount set to 1. everywhere\n",
    "    discount = jnp.ones_like(neg_efe)\n",
    "    recurrent_fn_output = mctx.RecurrentFnOutput(\n",
    "        reward=neg_efe,\n",
    "        discount=discount,\n",
    "        prior_logits=jnp.log(agent.E),\n",
    "        value=jnp.zeros_like(neg_efe))\n",
    "    next_embedding = embedding + 1\n",
    "    return recurrent_fn_output, next_embedding\n",
    "\n",
    "  return recurrent_fn\n",
    "\n",
    "# policy_output = gumber_si_policy(\n",
    "#     agents,\n",
    "#     rng_key,\n",
    "#     root,\n",
    "#     recurrent_fn,\n",
    "#     num_simulations=32,\n",
    "#     tree=None,\n",
    "#     max_nodes=48\n",
    "# )\n",
    "# tree = policy_output.search_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_si_policy(\n",
    "    params: chex.ArrayTree,\n",
    "    rng_key: chex.PRNGKey,\n",
    "    root: base.RootFnOutput,\n",
    "    decision_recurrent_fn: base.DecisionRecurrentFn,\n",
    "    chance_recurrent_fn: base.ChanceRecurrentFn,\n",
    "    num_simulations: int,\n",
    "    invalid_actions: Optional[chex.Array] = None,\n",
    "    max_depth: Optional[int] = None,\n",
    "    loop_fn: base.LoopFn = jax.lax.fori_loop,\n",
    "    *,\n",
    "    qtransform: base.QTransform = qtransforms.qtransform_by_parent_and_siblings,\n",
    "    dirichlet_fraction: chex.Numeric = 0.25,\n",
    "    dirichlet_alpha: chex.Numeric = 0.3,\n",
    "    pb_c_init: chex.Numeric = 1.25,\n",
    "    pb_c_base: chex.Numeric = 19652,\n",
    "    temperature: chex.Numeric = 1.0) -> base.PolicyOutput[None]:\n",
    "  \"\"\"Runs Stochastic MuZero search.\n",
    "\n",
    "  Implements search as described in the Stochastic MuZero paper:\n",
    "    (https://openreview.net/forum?id=X6D9bAHhBQ1).\n",
    "\n",
    "  In the shape descriptions, `B` denotes the batch dimension.\n",
    "  Args:\n",
    "    params: params to be forwarded to root and recurrent functions.\n",
    "    rng_key: random number generator state, the key is consumed.\n",
    "    root: a `(prior_logits, value, embedding)` `RootFnOutput`. The\n",
    "      `prior_logits` are from a policy network. The shapes are `([B,\n",
    "      num_actions], [B], [B, ...])`, respectively.\n",
    "    decision_recurrent_fn: a callable to be called on the leaf decision nodes\n",
    "      and unvisited actions retrieved by the simulation step, which takes as\n",
    "      args `(params, rng_key, action, state_embedding)` and returns a\n",
    "      `(DecisionRecurrentFnOutput, afterstate_embedding)`.\n",
    "    chance_recurrent_fn:  a callable to be called on the leaf chance nodes and\n",
    "      unvisited actions retrieved by the simulation step, which takes as args\n",
    "      `(params, rng_key, chance_outcome, afterstate_embedding)` and returns a\n",
    "      `(ChanceRecurrentFnOutput, state_embedding)`.\n",
    "    num_simulations: the number of simulations.\n",
    "    invalid_actions: a mask with invalid actions. Invalid actions have ones,\n",
    "      valid actions have zeros in the mask. Shape `[B, num_actions]`.\n",
    "    max_depth: maximum search tree depth allowed during simulation.\n",
    "    loop_fn: Function used to run the simulations. It may be required to pass\n",
    "      hk.fori_loop if using this function inside a Haiku module.\n",
    "    qtransform: function to obtain completed Q-values for a node.\n",
    "    dirichlet_fraction: float from 0 to 1 interpolating between using only the\n",
    "      prior policy or just the Dirichlet noise.\n",
    "    dirichlet_alpha: concentration parameter to parametrize the Dirichlet\n",
    "      distribution.\n",
    "    pb_c_init: constant c_1 in the PUCT formula.\n",
    "    pb_c_base: constant c_2 in the PUCT formula.\n",
    "    temperature: temperature for acting proportionally to `visit_counts**(1 /\n",
    "      temperature)`.\n",
    "\n",
    "  Returns:\n",
    "    `PolicyOutput` containing the proposed action, action_weights and the used\n",
    "    search tree.\n",
    "  \"\"\"\n",
    "\n",
    "  num_actions = root.prior_logits.shape[-1]\n",
    "\n",
    "  rng_key, dirichlet_rng_key, search_rng_key = jax.random.split(rng_key, 3)\n",
    "\n",
    "  # Adding Dirichlet noise.\n",
    "  noisy_logits = _get_logits_from_probs(\n",
    "      _add_dirichlet_noise(\n",
    "          dirichlet_rng_key,\n",
    "          jax.nn.softmax(root.prior_logits),\n",
    "          dirichlet_fraction=dirichlet_fraction,\n",
    "          dirichlet_alpha=dirichlet_alpha))\n",
    "\n",
    "  root = root.replace(\n",
    "      prior_logits=_mask_invalid_actions(noisy_logits, invalid_actions))\n",
    "\n",
    "  # construct a dummy afterstate embedding\n",
    "  batch_size = jax.tree_util.tree_leaves(root.embedding)[0].shape[0]\n",
    "  dummy_action = jnp.zeros([batch_size], dtype=jnp.int32)\n",
    "  dummy_output, dummy_afterstate_embedding = decision_recurrent_fn(\n",
    "      params, rng_key, dummy_action, root.embedding)\n",
    "  num_chance_outcomes = dummy_output.chance_logits.shape[-1]\n",
    "\n",
    "  root = root.replace(\n",
    "      # pad action logits with num_chance_outcomes so dim is A + C\n",
    "      prior_logits=jnp.concatenate([\n",
    "          root.prior_logits,\n",
    "          jnp.full([batch_size, num_chance_outcomes], fill_value=-jnp.inf)\n",
    "      ], axis=-1),\n",
    "      # replace embedding with wrapper.\n",
    "      embedding=base.StochasticRecurrentState(\n",
    "          state_embedding=root.embedding,\n",
    "          afterstate_embedding=dummy_afterstate_embedding,\n",
    "          is_decision_node=jnp.ones([batch_size], dtype=bool)))\n",
    "\n",
    "  # Stochastic MuZero Change: We need to be able to tell if different nodes are\n",
    "  # decision or chance. This is accomplished by imposing a special structure\n",
    "  # on the embeddings stored in each node. Each embedding is an instance of\n",
    "  # StochasticRecurrentState which maintains this information.\n",
    "  recurrent_fn = _make_stochastic_recurrent_fn(\n",
    "      decision_node_fn=decision_recurrent_fn,\n",
    "      chance_node_fn=chance_recurrent_fn,\n",
    "      num_actions=num_actions,\n",
    "      num_chance_outcomes=num_chance_outcomes,\n",
    "  )\n",
    "\n",
    "  # Running the search.\n",
    "\n",
    "  interior_decision_node_selection_fn = functools.partial(\n",
    "      action_selection.muzero_action_selection,\n",
    "      pb_c_base=pb_c_base,\n",
    "      pb_c_init=pb_c_init,\n",
    "      qtransform=qtransform)\n",
    "\n",
    "  interior_action_selection_fn = _make_stochastic_action_selection_fn(\n",
    "      interior_decision_node_selection_fn, num_actions)\n",
    "\n",
    "  root_action_selection_fn = functools.partial(\n",
    "      interior_action_selection_fn, depth=0)\n",
    "\n",
    "  search_tree = search.search(\n",
    "      params=params,\n",
    "      rng_key=search_rng_key,\n",
    "      root=root,\n",
    "      recurrent_fn=recurrent_fn,\n",
    "      root_action_selection_fn=root_action_selection_fn,\n",
    "      interior_action_selection_fn=interior_action_selection_fn,\n",
    "      num_simulations=num_simulations,\n",
    "      max_depth=max_depth,\n",
    "      invalid_actions=invalid_actions,\n",
    "      loop_fn=loop_fn)\n",
    "\n",
    "  # Sampling the proposed action proportionally to the visit counts.\n",
    "  search_tree = _mask_tree(search_tree, num_actions, 'decision')\n",
    "  summary = search_tree.summary()\n",
    "  action_weights = summary.visit_probs\n",
    "  action_logits = _apply_temperature(\n",
    "      _get_logits_from_probs(action_weights), temperature)\n",
    "  action = jax.random.categorical(rng_key, action_logits)\n",
    "  return base.PolicyOutput(\n",
    "      action=action, action_weights=action_weights, search_tree=search_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the subtree corresponding to the chosen action\n",
    "tree = mctx.get_subtree(tree, action)\n",
    "\n",
    "# go to next environment state\n",
    "\n",
    "batch_keys = jr.split(key, batch_size + 1)\n",
    "_keys = keys[:batch_size]\n",
    "key = keys[-1]\n",
    "obs, env = env.step(_keys, actions)\n",
    "\n",
    "# reset the search tree where the environment has terminated\n",
    "tree = mctx.reset_search_tree(tree, env.terminated)\n",
    "\n",
    "# new search with subtree\n",
    "# (max_nodes has no effect when a tree is passed) \n",
    "policy_ouput = efe_policy(\n",
    "    params,\n",
    "    rng_key,\n",
    "    root,\n",
    "    recurrent_fn,\n",
    "    num_simulations=32,\n",
    "    tree=tree\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
